{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBE6ReVlTJLnSWgjIbx5gV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandureddy23/Face-Recognition-based-login-system/blob/main/Small_Project_2_write_a_ML_program_to_diagnose_breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmlECtTb-awX",
        "outputId": "1dbca029-bd59-4552-d31d-f3198f07537e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: Random Forest\n",
            "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 150}\n",
            "Cross-validation scores: [0.96703297 0.93406593 0.97802198 0.95604396 0.94505495]\n",
            "Average cross-validation score: 0.956043956043956\n",
            "Test Accuracy: 0.9649122807017544\n",
            "Precision: 0.958904109589041\n",
            "Recall: 0.9859154929577465\n",
            "F1 Score: 0.9722222222222222\n",
            "\n",
            "\n",
            "Classifier: AdaBoost\n",
            "Best Parameters: {'learning_rate': 1.0, 'n_estimators': 150}\n",
            "Cross-validation scores: [1.         0.97802198 1.         0.97802198 0.93406593]\n",
            "Average cross-validation score: 0.9780219780219781\n",
            "Test Accuracy: 0.9736842105263158\n",
            "Precision: 0.9722222222222222\n",
            "Recall: 0.9859154929577465\n",
            "F1 Score: 0.979020979020979\n",
            "\n",
            "\n",
            "Classifier: Logistic Regression\n",
            "Best Parameters: {'C': 100}\n",
            "Cross-validation scores: [0.95604396 0.96703297 0.98901099 0.97802198 0.94505495]\n",
            "Average cross-validation score: 0.9670329670329672\n",
            "Test Accuracy: 0.956140350877193\n",
            "Precision: 0.9459459459459459\n",
            "Recall: 0.9859154929577465\n",
            "F1 Score: 0.9655172413793103\n",
            "\n",
            "\n",
            "Classifier: KNN\n",
            "Best Parameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
            "Cross-validation scores: [0.97802198 0.9010989  0.95604396 0.87912088 0.91208791]\n",
            "Average cross-validation score: 0.9252747252747253\n",
            "Test Accuracy: 0.9473684210526315\n",
            "Precision: 0.9333333333333333\n",
            "Recall: 0.9859154929577465\n",
            "F1 Score: 0.9589041095890412\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Load the dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split dataset into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define classifiers\n",
        "classifiers = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),  # Increased max_iter\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for each classifier\n",
        "for name, classifier in classifiers.items():\n",
        "    print(f\"Classifier: {name}\")\n",
        "\n",
        "    # Define hyperparameters grid for GridSearchCV\n",
        "    param_grid = {}\n",
        "\n",
        "    if name == 'Random Forest':\n",
        "        param_grid = {\n",
        "            'n_estimators': [50, 100, 150],\n",
        "            'max_depth': [None, 5, 10, 20],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "    elif name == 'AdaBoost':\n",
        "        param_grid = {\n",
        "            'n_estimators': [50, 100, 150],\n",
        "            'learning_rate': [0.01, 0.1, 1.0]\n",
        "        }\n",
        "    elif name == 'Logistic Regression':\n",
        "        param_grid = {\n",
        "            'C': [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "        }\n",
        "\n",
        "        # Increase the number of iterations\n",
        "        classifier.max_iter = 10000  # You can adjust the value accordingly\n",
        "\n",
        "    elif name == 'KNN':\n",
        "        param_grid = {\n",
        "            'n_neighbors': [3, 5, 7],\n",
        "            'weights': ['uniform', 'distance']\n",
        "        }\n",
        "\n",
        "    # Perform GridSearchCV\n",
        "    grid_search = GridSearchCV(classifier, param_grid, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best parameters\n",
        "    best_params = grid_search.best_params_\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "\n",
        "    # Best estimator\n",
        "    best_classifier = grid_search.best_estimator_\n",
        "\n",
        "    # Perform k-fold cross-validation\n",
        "    cv_scores = cross_val_score(best_classifier, X_train, y_train, cv=5)\n",
        "    print(\"Cross-validation scores:\", cv_scores)\n",
        "    print(\"Average cross-validation score:\", np.mean(cv_scores))\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    y_pred = best_classifier.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    test_precision = precision_score(y_test, y_pred)\n",
        "    test_recall = recall_score(y_test, y_pred)\n",
        "    test_f1_score = f1_score(y_test, y_pred)\n",
        "\n",
        "    print(\"Test Accuracy:\", test_accuracy)\n",
        "    print(\"Precision:\", test_precision)\n",
        "    print(\"Recall:\", test_recall)\n",
        "    print(\"F1 Score:\", test_f1_score)\n",
        "\n",
        "    # Calculate sensitivity (precision) and specificity\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "    print(\"\\n\")\n"
      ]
    }
  ]
}